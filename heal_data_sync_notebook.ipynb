{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42df9676",
   "metadata": {},
   "source": [
    "# HEAL DATA SYNC - Jupyter Notebook Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a99ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install necessary dependencies (if not installed)\n",
    "!pip install openai langchain qdrant-client fastapi uvicorn langsmith ragas chainlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.graphs import Graph\n",
    "from langsmith import LangSmith\n",
    "from ragas import Ragas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27063843",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set API keys and environment variables\n",
    "OPENAI_API_KEY = \"your_openai_api_key\"\n",
    "QDRANT_URL = \"http://localhost:6333\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e50806",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initialize Embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e7cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Qdrant Vector Database\n",
    "vector_db = Qdrant(embedding_function=embeddings, url=QDRANT_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d41366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize LangGraph\n",
    "graph = Graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_pipeline(query: str):\n",
    "    \"\"\"Handles end-to-end data retrieval and processing.\"\"\"\n",
    "    embedding = embeddings.embed_query(query)\n",
    "    results = vector_db.similarity_search_by_vector(embedding)\n",
    "    response = llm.invoke(\" \".join([doc.page_content for doc in results]))\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e94095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test LLM response\n",
    "query_text = \"Explain the impact of AI on healthcare.\"\n",
    "response = data_pipeline(query_text)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe768320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Monitoring\n",
    "monitoring = LangSmith(project_name=\"HEAL_DATA_SYNC\")\n",
    "monitoring.track_pipeline(data_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aef6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Evaluation\n",
    "evaluation = Ragas()\n",
    "\n",
    "def evaluate_response(response: str, query: str):\n",
    "    \"\"\"Evaluate response quality using RAGAS.\"\"\"\n",
    "    return evaluation.score_response(query, response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b112809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test Evaluation\n",
    "score = evaluate_response(response, query_text)\n",
    "print(\"Evaluation Score:\", score)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}